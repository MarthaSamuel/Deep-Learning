{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Facial Recognition with Deep Learning in Keras Using CNN\n",
    "Project 2 \n",
    "\n",
    "DESCRIPTION\n",
    "\n",
    "Problem Statement:\n",
    "Facial recognition is a biometric alternative that measures unique characteristics of a human\n",
    "face. Applications available today include flight check in, tagging friends and family members in\n",
    "photos, and “tailored” advertising. You are a computer vision engineer who needs to develop a\n",
    "face recognition programme with deep convolutional neural networks.\n",
    "Objective: Use a deep convolutional neural network to perform facial recognition using Keras.\n",
    "Dataset Details:\n",
    "ORL face database composed of 400 images of size 112 x 92. There are 40 people, 10 images\n",
    "per person. The images were taken at different times, lighting and facial expressions. The faces\n",
    "are in an upright position in frontal view, with a slight left-right rotation.\n",
    "Link to the Dataset: https://www.dropbox.com/s/i7uzp5yxk7wruva/ORL_faces.npz?dl=0\n",
    "Prerequisites:\n",
    "Keras\n",
    "Scikit Learn\n",
    "Steps to be followed:\n",
    "1. Input the required libraries\n",
    "2. Load the dataset after loading the dataset, you have to normalize every image.\n",
    "3. Split the dataset\n",
    "4. Transform the images to equal sizes to feed in CNN\n",
    "5. Build a CNN model that has 3 main layers:\n",
    "\n",
    "i. Convolutional Layer\n",
    "ii. Pooling Layer\n",
    "iii. Fully Connected Layer\n",
    "\n",
    "6. Train the model\n",
    "7. Plot the result\n",
    "8. Iterate the model until the accuracy is above 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 10304)\n",
      "(240,)\n",
      "(160, 10304)\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "trainX = np.load('trainX.npy', allow_pickle='TRUE')\n",
    "trainY = np.load('trainY.npy', allow_pickle='TRUE')\n",
    "testX = np.load('testX.npy', allow_pickle='TRUE')\n",
    "testY = np.load('testY.npy', allow_pickle='TRUE')\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.min(), trainY.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have 20 people data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=20)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes= 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Number of channels =1, h, w reshape for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX =trainX.reshape(240, 112, 92, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = testX.reshape(160, 112, 92, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#view the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=92x112 at 0x7F9E77D650B8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.array_to_img(trainX[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=92x112 at 0x7F9E77D651D0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.array_to_img(trainX[20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "ownmodel = tf.keras.models.Sequential()\n",
    "ownmodel.add(tf.keras.layers.Reshape((112, 92, 1), input_shape=(112,92,1)))\n",
    "#normalize the input\n",
    "ownmodel.add(tf.keras.layers.BatchNormalization())\n",
    "ownmodel.add(tf.keras.layers.Conv2D(32, #no of filters \n",
    "                                 kernel_size=(3, 3), activation='relu'))          \n",
    "ownmodel.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) \n",
    "ownmodel.add(tf.keras.layers.Dropout(0.3))\n",
    "ownmodel.add(tf.keras.layers.Conv2D(64, #no of filters \n",
    "                                 kernel_size=(3, 3), activation='relu'))          \n",
    "ownmodel.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) \n",
    "ownmodel.add(tf.keras.layers.Dropout(0.3))\n",
    "ownmodel.add(tf.keras.layers.Conv2D(128, #no of filters \n",
    "                                 kernel_size=(3, 3), activation='relu'))          \n",
    "ownmodel.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) \n",
    "ownmodel.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "ownmodel.add(tf.keras.layers.Conv2D(256, #no of filters \n",
    "                                 kernel_size=(3, 3), activation='relu'))          \n",
    "ownmodel.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) \n",
    "ownmodel.add(tf.keras.layers.Dropout(0.3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#flatten the extracted features in a single dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ownmodel.add(tf.keras.layers.Flatten())\n",
    "ownmodel.add(tf.keras.layers.Dense(20, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Set optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 112, 92, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 92, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 110, 90, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 55, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 55, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 53, 43, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 7, 256)        295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                76820     \n",
      "=================================================================\n",
      "Total params: 464,664\n",
      "Trainable params: 464,662\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ownmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ownmodel.compile(optimizer='adam', loss ='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.8, \n",
    "                                            min_lr=0.0001)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0026 - acc: 1.0000 - val_loss: 0.2723 - val_acc: 0.9250\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2608 - val_acc: 0.9250\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2699 - val_acc: 0.9250\n",
      "Epoch 4/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.0167 - acc: 0.9955\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0156 - acc: 0.9958 - val_loss: 0.4164 - val_acc: 0.9062\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0576 - acc: 0.9750 - val_loss: 0.3407 - val_acc: 0.9000\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.3458 - val_acc: 0.8938\n",
      "Epoch 7/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.0116 - acc: 0.9955\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0120 - acc: 0.9958 - val_loss: 0.2871 - val_acc: 0.9125\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0188 - acc: 0.9917 - val_loss: 0.3081 - val_acc: 0.9187\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0092 - acc: 0.9958 - val_loss: 0.2876 - val_acc: 0.9187\n",
      "Epoch 10/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0022 - acc: 1.0000 - val_loss: 0.2642 - val_acc: 0.9187\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2615 - val_acc: 0.9187\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2584 - val_acc: 0.9250\n",
      "Epoch 13/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.2570 - val_acc: 0.9250\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 3.2061e-04 - acc: 1.0000 - val_loss: 0.2562 - val_acc: 0.9250\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 7.6315e-04 - acc: 1.0000 - val_loss: 0.2493 - val_acc: 0.9250\n",
      "Epoch 16/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 8.8878e-04 - acc: 1.0000\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 8.6359e-04 - acc: 1.0000 - val_loss: 0.2508 - val_acc: 0.9250\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2460 - val_acc: 0.9250\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 0.2408 - val_acc: 0.9250\n",
      "Epoch 19/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 0.2409 - val_acc: 0.9250\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 5.2721e-04 - acc: 1.0000 - val_loss: 0.2384 - val_acc: 0.9375\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.2277 - val_acc: 0.9375\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 6.1412e-04 - acc: 1.0000 - val_loss: 0.2177 - val_acc: 0.9438\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 3.2759e-04 - acc: 1.0000 - val_loss: 0.2160 - val_acc: 0.9438\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 7.5170e-04 - acc: 1.0000 - val_loss: 0.2156 - val_acc: 0.9438\n",
      "Epoch 25/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 2.1822e-04 - acc: 1.0000\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 2.0685e-04 - acc: 1.0000 - val_loss: 0.2151 - val_acc: 0.9438\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 9.5421e-04 - acc: 1.0000 - val_loss: 0.2153 - val_acc: 0.9438\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 9.7263e-04 - acc: 1.0000 - val_loss: 0.2159 - val_acc: 0.9438\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 8.2317e-04 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 0.9438\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 5.6239e-04 - acc: 1.0000 - val_loss: 0.2152 - val_acc: 0.9438\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 9.4506e-04 - acc: 1.0000 - val_loss: 0.2174 - val_acc: 0.9438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e77a83470>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ownmodel.fit(trainX, trainY, validation_data=(testX, testY), epochs=30, batch_size=16,callbacks=[learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 0.207454, final accuracy: 0.968750\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = ownmodel.evaluate(testX, testY, verbose=0)\n",
    "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Resnet Transfer learning\n",
    "-prepare data to have 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 10304)\n",
      "(240,)\n",
      "(160, 10304)\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "trainX = np.load('trainX.npy', allow_pickle='TRUE')\n",
    "trainY = np.load('trainY.npy', allow_pickle='TRUE')\n",
    "testX = np.load('testX.npy', allow_pickle='TRUE')\n",
    "testY = np.load('testY.npy', allow_pickle='TRUE')\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=20)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes= 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape(240, 112, 92)\n",
    "testX = testX. reshape(160, 112, 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.repeat(trainX[..., np.newaxis], 3,-1)\n",
    "testX = np.repeat(testX[..., np.newaxis], 3, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 112, 92, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 112, 92, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create resnet model and download pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model50 = tf.keras.applications.resnet50.ResNet50(include_top=False # we will make our own FC layer\n",
    "                                               ,input_shape=(112, 92, 3),\n",
    "                                               weights= 'imagenet', classes=20,input_tensor=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the base layers to not trainable and we will add  our own layers\n",
    "for layer in model50.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv5_block3_out/Relu:0' shape=(?, 4, 3, 2048) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model50.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add FC layers for our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get the output tensor\n",
    "x = model50.output\n",
    "\n",
    "#Flatten the output in single dim\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "#Add one intermediate dense layer\n",
    "x = tf.keras.layers.Dense(2000, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(500, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "\n",
    "\n",
    "#lets then add the final classification layer(20 modes)\n",
    "prediction50 = tf.keras.layers.Dense(20, activation = 'softmax')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model50 = tf.keras.models.Model(inputs=model50.input, #Pre-trained model input as input layer\n",
    "                                   outputs=prediction50)   #Output layer added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 112, 92, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 118, 98, 3)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 56, 46, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 56, 46, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 56, 46, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 58, 48, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 28, 23, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 28, 23, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 28, 23, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 28, 23, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 28, 23, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 28, 23, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 28, 23, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 28, 23, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 28, 23, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 28, 23, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 28, 23, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 28, 23, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 28, 23, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 28, 23, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 23, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 28, 23, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 28, 23, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 14, 12, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 14, 12, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 14, 12, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 14, 12, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 14, 12, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 14, 12, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 14, 12, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 14, 12, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 14, 12, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 14, 12, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 14, 12, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 14, 12, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 14, 12, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 14, 12, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 14, 12, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 12, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 14, 12, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 14, 12, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 6, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 6, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 6, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 6, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 6, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 6, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 6, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 6, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 6, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 6, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 6, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 6, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 6, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 6, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 6, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 6, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 6, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 6, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 6, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 6, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 6, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 6, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 6, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 6, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 6, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 6, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 3, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 3, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 3, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 3, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 3, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 3, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 3, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 3, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 3, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 3, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 3, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 3, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 3, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 3, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 3, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 3, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 24576)        0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2000)         49154000    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1000)         2001000     dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          500500      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          100200      dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          20100       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 20)           2020        dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 75,365,532\n",
      "Trainable params: 51,777,820\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.callbacks import ReduceLROnPlateau #keras.io/api/callbacks\n",
    "\n",
    "\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.7, \n",
    "                                            min_lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_model50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#trainX =trainX.reshape(240, 112, 92, 3)\n",
    "#testX = testX.reshape(160, 112, 92, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 20s 82ms/sample - loss: 6.3496 - acc: 0.2000 - val_loss: 5.6908 - val_acc: 0.1187\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 1.0441 - acc: 0.7125 - val_loss: 7.1575 - val_acc: 0.0812\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 0.2104 - acc: 0.9417 - val_loss: 5.3204 - val_acc: 0.2438\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 0.0145 - acc: 0.9958 - val_loss: 11.2149 - val_acc: 0.1000\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 5.5076 - val_acc: 0.2625\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 5.4669 - val_acc: 0.1875\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 4.9022e-04 - acc: 1.0000 - val_loss: 5.2563 - val_acc: 0.1813\n",
      "Epoch 8/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 4.1306e-04 - acc: 1.0000\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 4.0497e-04 - acc: 1.0000 - val_loss: 5.2583 - val_acc: 0.1937\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 0.0177 - acc: 0.9958 - val_loss: 4.8833 - val_acc: 0.2125\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 0.0575 - acc: 0.9958 - val_loss: 4.7646 - val_acc: 0.2062\n",
      "Epoch 11/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 8.2664e-04 - acc: 1.0000\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 0.0018 - acc: 1.0000 - val_loss: 5.2935 - val_acc: 0.2125\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 4.7477 - val_acc: 0.2125\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 3.0574e-04 - acc: 1.0000 - val_loss: 4.5834 - val_acc: 0.2188\n",
      "Epoch 14/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 4.0224e-04 - acc: 1.0000\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "240/240 [==============================] - 15s 61ms/sample - loss: 8.0869e-04 - acc: 1.0000 - val_loss: 4.6886 - val_acc: 0.2188\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 1.8011e-04 - acc: 1.0000 - val_loss: 4.9238 - val_acc: 0.2188\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 3.5324e-04 - acc: 1.0000 - val_loss: 5.0519 - val_acc: 0.2188\n",
      "Epoch 17/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.5253e-04 - acc: 1.0000\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 1.4653e-04 - acc: 1.0000 - val_loss: 5.0941 - val_acc: 0.2062\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 15s 60ms/sample - loss: 1.6731e-04 - acc: 1.0000 - val_loss: 5.0776 - val_acc: 0.2188\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 8.8815e-04 - acc: 1.0000 - val_loss: 5.3717 - val_acc: 0.2000\n",
      "Epoch 20/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.1618e-04 - acc: 1.0000\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 1.1935e-04 - acc: 1.0000 - val_loss: 5.4473 - val_acc: 0.2000\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 1.1367e-04 - acc: 1.0000 - val_loss: 5.4574 - val_acc: 0.2000\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 1.2095e-04 - acc: 1.0000 - val_loss: 5.4558 - val_acc: 0.2000\n",
      "Epoch 23/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 9.7149e-05 - acc: 1.0000\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 9.3288e-05 - acc: 1.0000 - val_loss: 5.4530 - val_acc: 0.2000\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 14s 59ms/sample - loss: 8.9203e-05 - acc: 1.0000 - val_loss: 5.4531 - val_acc: 0.2000\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 14s 59ms/sample - loss: 1.3511e-04 - acc: 1.0000 - val_loss: 5.4432 - val_acc: 0.2000\n",
      "Epoch 26/30\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 1.4086e-04 - acc: 1.0000\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 1.3278e-04 - acc: 1.0000 - val_loss: 5.4357 - val_acc: 0.2000\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 2.9953e-04 - acc: 1.0000 - val_loss: 5.4723 - val_acc: 0.2125\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 14s 60ms/sample - loss: 8.8430e-05 - acc: 1.0000 - val_loss: 5.4769 - val_acc: 0.2125\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 14s 59ms/sample - loss: 7.5341e-05 - acc: 1.0000 - val_loss: 5.4789 - val_acc: 0.2125\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 14s 59ms/sample - loss: 5.7066e-05 - acc: 1.0000 - val_loss: 5.4773 - val_acc: 0.2125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e717aef98>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_model50.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "                epochs=30, batch_size =16, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model101= tf.keras.applications.resnet.ResNet101(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=(112, 92, 3), classes=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the base layers to not trainable and we will add  our own layers\n",
    "for layer in model101.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv5_block3_out_1/Relu:0' shape=(?, 4, 3, 2048) dtype=float32>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model101.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get the output tensor\n",
    "x = model101.output\n",
    "\n",
    "#Flatten the output in single dim\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "#Add one intermediate dense layer\n",
    "#x = tf.keras.layers.Dense(2000, activation='relu')(x)\n",
    "#x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(500, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "\n",
    "\n",
    "#lets then add the final classification layer(20 modes)\n",
    "prediction101 = tf.keras.layers.Dense(20, activation = 'softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model101 = tf.keras.models.Model(inputs=model101.input,\n",
    "                                   outputs=prediction101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 112, 92, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 118, 98, 3)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 56, 46, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 56, 46, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 56, 46, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 58, 48, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 28, 23, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 28, 23, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 28, 23, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 28, 23, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 28, 23, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 28, 23, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 28, 23, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 28, 23, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 28, 23, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 28, 23, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 28, 23, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 28, 23, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 28, 23, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 28, 23, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 23, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 28, 23, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 28, 23, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 14, 12, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 14, 12, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 14, 12, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 14, 12, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 14, 12, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 14, 12, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 14, 12, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 14, 12, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 14, 12, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 14, 12, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 14, 12, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 14, 12, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 14, 12, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 14, 12, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 14, 12, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 12, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 14, 12, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 14, 12, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 6, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 6, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 6, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 6, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 6, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 6, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 6, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 6, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 6, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 6, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 6, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 6, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 6, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 6, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 6, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 6, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 6, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 6, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 6, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 6, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 6, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 6, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 6, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 6, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 6, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 6, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 7, 6, 256)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 7, 6, 256)    0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 7, 6, 1024)   0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 7, 6, 1024)   0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 7, 6, 256)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 7, 6, 256)    0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 7, 6, 1024)   0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 7, 6, 1024)   0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 7, 6, 256)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 7, 6, 256)    0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 7, 6, 1024)   0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 7, 6, 1024)   0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 7, 6, 1024)   0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 7, 6, 1024)   0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 7, 6, 1024)   0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 7, 6, 1024)   0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 7, 6, 1024)   0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 7, 6, 1024)   0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 7, 6, 1024)   0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 7, 6, 1024)   0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 7, 6, 1024)   0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 7, 6, 1024)   0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 7, 6, 1024)   0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 7, 6, 1024)   0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 7, 6, 1024)   0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 7, 6, 1024)   0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 7, 6, 1024)   0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 7, 6, 1024)   0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 7, 6, 1024)   0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 7, 6, 1024)   0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 7, 6, 1024)   0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 7, 6, 1024)   0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 7, 6, 1024)   0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 7, 6, 1024)   0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 7, 6, 1024)   0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 7, 6, 1024)   0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 7, 6, 1024)   0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 7, 6, 1024)   0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 7, 6, 256)    262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 7, 6, 256)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 7, 6, 256)    590080      conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 7, 6, 256)    1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 7, 6, 256)    0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 7, 6, 1024)   263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 7, 6, 1024)   4096        conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 7, 6, 1024)   0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 7, 6, 1024)   0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 3, 512)    524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 3, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 3, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 3, 2048)   2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 3, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 3, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 3, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 3, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 3, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 3, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 3, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 3, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 3, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 3, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 3, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 3, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 24576)        0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 500)          12288500    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 200)          100200      dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 100)          20100       dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 20)           2020        dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 55,068,996\n",
      "Trainable params: 12,410,820\n",
      "Non-trainable params: 42,658,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model101.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model101.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 160 samples\n",
      "Epoch 1/25\n",
      "240/240 [==============================] - 30s 126ms/sample - loss: 1.7625 - acc: 0.5833 - val_loss: 6.9282 - val_acc: 0.1312\n",
      "Epoch 2/25\n",
      "240/240 [==============================] - 20s 84ms/sample - loss: 0.1517 - acc: 0.9708 - val_loss: 11.1720 - val_acc: 0.1312\n",
      "Epoch 3/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 0.0870 - acc: 0.9708 - val_loss: 17.8078 - val_acc: 0.1000\n",
      "Epoch 4/25\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "240/240 [==============================] - 21s 88ms/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 16.7724 - val_acc: 0.0875\n",
      "Epoch 5/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 0.0131 - acc: 0.9917 - val_loss: 15.6284 - val_acc: 0.1187\n",
      "Epoch 6/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 2.9509e-04 - acc: 1.0000 - val_loss: 17.0319 - val_acc: 0.1375\n",
      "Epoch 7/25\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 2.9171e-04 - acc: 1.0000\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "240/240 [==============================] - 20s 84ms/sample - loss: 0.0015 - acc: 1.0000 - val_loss: 17.7308 - val_acc: 0.1250\n",
      "Epoch 8/25\n",
      "240/240 [==============================] - 20s 84ms/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 17.2670 - val_acc: 0.1375\n",
      "Epoch 9/25\n",
      "240/240 [==============================] - 20s 84ms/sample - loss: 4.4772e-04 - acc: 1.0000 - val_loss: 17.2134 - val_acc: 0.1375\n",
      "Epoch 10/25\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 4.6080e-05 - acc: 1.0000\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 4.4283e-05 - acc: 1.0000 - val_loss: 17.2024 - val_acc: 0.1375\n",
      "Epoch 11/25\n",
      "240/240 [==============================] - 20s 84ms/sample - loss: 5.5654e-05 - acc: 1.0000 - val_loss: 17.1950 - val_acc: 0.1375\n",
      "Epoch 12/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 5.7516e-05 - acc: 1.0000 - val_loss: 17.1902 - val_acc: 0.1375\n",
      "Epoch 13/25\n",
      "224/240 [===========================>..] - ETA: 0s - loss: 4.1322e-05 - acc: 1.0000\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "240/240 [==============================] - 21s 86ms/sample - loss: 3.8583e-05 - acc: 1.0000 - val_loss: 17.1802 - val_acc: 0.1375\n",
      "Epoch 14/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 8.7183e-05 - acc: 1.0000 - val_loss: 17.1744 - val_acc: 0.1375\n",
      "Epoch 15/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 1.2690e-04 - acc: 1.0000 - val_loss: 17.1662 - val_acc: 0.1375\n",
      "Epoch 16/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 2.0822e-04 - acc: 1.0000 - val_loss: 17.1418 - val_acc: 0.1375\n",
      "Epoch 17/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 1.9565e-04 - acc: 1.0000 - val_loss: 17.1157 - val_acc: 0.1375\n",
      "Epoch 18/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 6.2074e-05 - acc: 1.0000 - val_loss: 17.0964 - val_acc: 0.1375\n",
      "Epoch 19/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 4.5488e-04 - acc: 1.0000 - val_loss: 16.9465 - val_acc: 0.1375\n",
      "Epoch 20/25\n",
      "240/240 [==============================] - 20s 84ms/sample - loss: 9.5430e-06 - acc: 1.0000 - val_loss: 16.9111 - val_acc: 0.1375\n",
      "Epoch 21/25\n",
      "240/240 [==============================] - 20s 84ms/sample - loss: 1.8572e-05 - acc: 1.0000 - val_loss: 16.9017 - val_acc: 0.1375\n",
      "Epoch 22/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 7.5388e-04 - acc: 1.0000 - val_loss: 16.8481 - val_acc: 0.1375\n",
      "Epoch 23/25\n",
      "240/240 [==============================] - 20s 84ms/sample - loss: 1.0015e-05 - acc: 1.0000 - val_loss: 16.7896 - val_acc: 0.1375\n",
      "Epoch 24/25\n",
      "240/240 [==============================] - 20s 85ms/sample - loss: 1.5760e-04 - acc: 1.0000 - val_loss: 16.8043 - val_acc: 0.1375\n",
      "Epoch 25/25\n",
      "240/240 [==============================] - 21s 86ms/sample - loss: 7.1008e-05 - acc: 1.0000 - val_loss: 16.8336 - val_acc: 0.1375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9eae8ae4a8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model101.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "                epochs=25, batch_size =16,callbacks=[learning_rate_reduction] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we use the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.load('testX.npy', allow_pickle='TRUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = testX. reshape(160, 112, 92, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 20)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction = ownmodel.predict(testX)\n",
    "final_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Misclassifications 5\n"
     ]
    }
   ],
   "source": [
    "print('Number of Misclassifications', ((final_prediction.argmax(axis=1))!=(testY.argmax(axis=1))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  9,  9,  9,  7,  9,  9,  9,  7, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 19, 14, 14, 14, 14, 14, 14,\n",
       "       14, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 15, 18, 18, 18, 15, 18, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.load('trainX.npy', allow_pickle='TRUE')\n",
    "#trainY = np.load('trainY.npy', allow_pickle='TRUE')\n",
    "#testX = np.load('testX.npy', allow_pickle='TRUE')\n",
    "#testY = np.load('testY.npy', allow_pickle='TRUE')\n",
    "#print(trainX.shape)\n",
    "trainX = trainX. reshape(240, 112, 92, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 160 samples\n",
      "Epoch 1/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 2.5932e-04 - acc: 1.0000 - val_loss: 0.2278 - val_acc: 0.9563\n",
      "Epoch 2/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 2.8268e-04 - acc: 1.0000 - val_loss: 0.2296 - val_acc: 0.9563\n",
      "Epoch 3/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 1.4593e-04 - acc: 1.0000 - val_loss: 0.2298 - val_acc: 0.9563\n",
      "Epoch 4/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 3.7119e-04 - acc: 1.0000 - val_loss: 0.2275 - val_acc: 0.9563\n",
      "Epoch 5/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 9.4190e-05 - acc: 1.0000 - val_loss: 0.2258 - val_acc: 0.9625\n",
      "Epoch 6/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 4.8168e-04 - acc: 1.0000 - val_loss: 0.2248 - val_acc: 0.9625\n",
      "Epoch 7/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 1.5761e-04 - acc: 1.0000 - val_loss: 0.2242 - val_acc: 0.9625\n",
      "Epoch 8/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2087 - val_acc: 0.9625\n",
      "Epoch 9/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 3.8779e-05 - acc: 1.0000 - val_loss: 0.2012 - val_acc: 0.9625\n",
      "Epoch 10/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 6.7308e-05 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9563\n",
      "Epoch 11/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 6.0216e-05 - acc: 1.0000 - val_loss: 0.2031 - val_acc: 0.9563\n",
      "Epoch 12/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 2.4406e-05 - acc: 1.0000 - val_loss: 0.2031 - val_acc: 0.9563\n",
      "Epoch 13/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 4.7435e-05 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9563\n",
      "Epoch 14/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 1.1537e-04 - acc: 1.0000 - val_loss: 0.2030 - val_acc: 0.9563\n",
      "Epoch 15/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 3.6834e-04 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9563\n",
      "Epoch 16/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 2.4214e-04 - acc: 1.0000 - val_loss: 0.2046 - val_acc: 0.9563\n",
      "Epoch 17/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9688\n",
      "Epoch 18/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 2.1627e-04 - acc: 1.0000 - val_loss: 0.1874 - val_acc: 0.9688\n",
      "Epoch 19/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 4.4242e-04 - acc: 1.0000 - val_loss: 0.2011 - val_acc: 0.9688\n",
      "Epoch 20/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 6.8911e-05 - acc: 1.0000 - val_loss: 0.2135 - val_acc: 0.9625\n",
      "Epoch 21/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 1.1425e-04 - acc: 1.0000 - val_loss: 0.2167 - val_acc: 0.9625\n",
      "Epoch 22/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 2.3515e-05 - acc: 1.0000 - val_loss: 0.2173 - val_acc: 0.9625\n",
      "Epoch 23/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 6.4942e-05 - acc: 1.0000 - val_loss: 0.2176 - val_acc: 0.9625\n",
      "Epoch 24/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 9.5082e-05 - acc: 1.0000 - val_loss: 0.2184 - val_acc: 0.9625\n",
      "Epoch 25/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 4.7211e-05 - acc: 1.0000 - val_loss: 0.2191 - val_acc: 0.9625\n",
      "Epoch 26/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0038 - acc: 0.9958 - val_loss: 0.2320 - val_acc: 0.9563\n",
      "Epoch 27/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0042 - acc: 0.9958 - val_loss: 0.2940 - val_acc: 0.9625\n",
      "Epoch 28/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2270 - val_acc: 0.9688\n",
      "Epoch 29/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 3.6662e-04 - acc: 1.0000 - val_loss: 0.2142 - val_acc: 0.9688\n",
      "Epoch 30/30\n",
      "240/240 [==============================] - 3s 14ms/sample - loss: 6.4911e-05 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9688\n"
     ]
    }
   ],
   "source": [
    "s=ownmodel.fit(trainX, trainY, validation_data=(testX, testY), epochs=30, batch_size=16,\n",
    "                   callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 25.1 MB/s eta 0:00:01     |█████████████████████████████   | 10.5 MB 25.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 82.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/site-packages (from matplotlib) (8.1.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 kiwisolver-1.3.1 matplotlib-3.3.4\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(s.history.keys())\n",
    "accuracy = s.history['acc']\n",
    "val_accuracy = s.history['val_acc']\n",
    "loss = s.history['loss']\n",
    "val_loss = s.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 1.15 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-1.15-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
